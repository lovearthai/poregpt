# ğŸ§¬ Nanopore Signal Tokenizer

> å°† Nanopore åŸå§‹ç”µæµä¿¡å·ï¼ˆ5 kHzï¼‰è½¬æ¢ä¸ºç¦»æ•£ token åºåˆ—ï¼Œç”¨äºä¸‹æ¸¸è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ GPTï¼‰å»ºæ¨¡ DNA/RNA åºåˆ—ã€‚

[![Python 3.10+](https://img.shields.io/badge/Python-3.10%2B-blue)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

---

## ğŸ” ç®€ä»‹
æœ¬å·¥å…·æä¾›ä¸¤ç§ Nanopore åŸå§‹ç”µæµä¿¡å·ï¼ˆå•ä½ï¼špAï¼‰çš„ token åŒ–æ–¹æ¡ˆï¼Œå¯å°†è¿ç»­ç”µæµä¿¡å·è½¬æ¢ä¸ºç»“æ„åŒ–ç¦»æ•£ç¬¦å·åºåˆ—ã€‚é€‚é…ä¸åŒå»ºæ¨¡éœ€æ±‚ï¼šé€‚ç”¨åœºæ™¯
Nanopore ä¿¡å·è¯­è¨€å»ºæ¨¡ï¼ˆSignal LMï¼‰ï¼›
æ— å‚è€ƒåºåˆ—çš„ RNA/DNA è¡¨å¾å­¦ä¹ ï¼›
å¤šæ¨¡æ€ç”Ÿç‰©ä¿¡æ¯å­¦åˆ†ææµç¨‹ï¼ˆpipelineï¼‰æ„å»ºã€‚

1. RVQ Tokenizerï¼ˆæ®‹å·®çŸ¢é‡é‡åŒ–ï¼‰
åŸºäºè‡ªç›‘ç£æ®‹å·®çŸ¢é‡é‡åŒ–ï¼ˆResidual VQï¼‰æ¨¡å‹å®ç°ä¿¡å· token åŒ–ï¼Œè¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š<|bwav:L1_5336|><|bwav:L2_7466|><|bwav:L3_6973|><|bwav:L4_6340|>

æ ¸å¿ƒç‰¹æ€§ï¼š
æ”¯æŒ L1~L4 å¤šå±‚çº§ token è¾“å‡ºï¼Œå¯çµæ´»é€‚é…ä¸åŒç²’åº¦çš„å»ºæ¨¡ä»»åŠ¡ï¼›
å…¼å®¹ FAST5 æ ¼å¼æ–‡ä»¶ä¸åŸå§‹æµ®ç‚¹ä¿¡å·æ•°ç»„ä¸¤ç§è¾“å…¥å½¢å¼ï¼›
å†…ç½®ä¿¡å·å½’ä¸€åŒ– + Butterworth æ»¤æ³¢æµç¨‹ï¼Œæå‡ token åŒ–é²æ£’æ€§ï¼›
æ”¯æŒé•¿ä¿¡å·åˆ†å—å¤„ç†ï¼ˆæ»‘åŠ¨çª—å£ + é‡å ç­–ç•¥ï¼‰ï¼Œé€‚é…é•¿åºåˆ—å»ºæ¨¡åœºæ™¯

2. KMeans Tokenizerï¼ˆKmeansèšç±»ï¼‰
åŸºäº faiss K-Means èšç±»ç®—æ³•å®ç°ä¿¡å· token åŒ–ï¼šå…ˆé€šè¿‡èšç±»ç”ŸæˆæŒ‡å®šæ•°é‡çš„èšç±»ä¸­å¿ƒï¼Œå†å°†ç”µæµä¿¡å·åˆ‡ç‰‡ä¸ºå›ºå®šç»´åº¦å‘é‡ï¼Œé€šè¿‡åŒ¹é…æœ€ç›¸ä¼¼çš„èšç±»ä¸­å¿ƒå‘é‡ï¼Œä»¥èšç±»ç¼–å·æ›¿æ¢åŸå§‹ä¿¡å·å®Œæˆ token åŒ–ã€‚æ³¨æ„ï¼šfaiss keansä¸æ”¯æŒint64ä¸ªå‘é‡çš„èšç±»ï¼Œæ‰€ä»¥ç›®å‰åªæ”¯æŒ2Bï¼ˆ20äº¿ï¼‰ä¸ªå‘é‡çš„èšç±»ã€‚

æœ¬å·¥å…·è½¬æ¢çš„æ ¼å¼ä¸º`<|bwav:5018|><|bwav:8156|><|bwav:23|><|bwav:5725|><|bwav:418|>`, ä¸åé¢çš„vq_tokenizeræ˜¯ä¸€æ ·çš„æ ¼å¼ã€‚

3. VQ tokenizer 

ä»…ä»…ä¸€å±‚çš„ç¦»æ•£åŒ–ï¼Œæ”¯æŒå°†ä¸€ä¸ªåŸå§‹ç”µæµä¿¡å·ï¼Œè½¬æ¢ä¸º `<|bwav:5808|><|bwav:702|><|bwav:330|><|bwav:6238|><|bwav:2432|>` æ ¼å¼ï¼Œå…¶ä¸­æ•°å­—ä»0æ‹åˆ°8191ï¼ˆåœ¨8k codebookæƒ…å†µä¸‹ï¼‰


## âš™ï¸ å®‰è£…

### ä»æºç å®‰è£…ï¼ˆæ¨èï¼‰

```bash
git clone https://github.com/lovearthai/nanopore_signal_tokenizer.git
cd nanopore_signal_tokenizer
pip install -e . 
#å¦‚æœé˜¿é‡ŒæºæŠ¥é”™ï¼Œåˆ‡æ¢æ¸…åæºæˆ–å®˜æ–¹æº 
pip install -e . \
  --no-build-isolation \
  -i https://pypi.tuna.tsinghua.edu.cn/simple/ \
  --extra-index-url https://pypi.org/simple/ \
  --trusted-host pypi.tuna.tsinghua.edu.cn \
  --trusted-host pypi.org \
  --trusted-host files.pythonhosted.org

pip install vector-quantize-pytorch -i https://pypi.org/simple/
conda install -c pytorch faiss-gpu  
```

##  VQ_tokenizer

### åˆå§‹åŒ– Tokenizer

```python
from nanopore_signal_tokenizer import VQTokenizer

tokenizer = VQTokenizer(
    model_ckpt="models/model_vq_8k_epoch10.pth",  # å¿…å¡«ï¼šé¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
    device="cuda",                                # å¯é€‰ï¼šè®¾å¤‡ï¼Œé»˜è®¤è‡ªåŠ¨é€‰ cuda/cpu
    token_batch_size=100                          # å¯é€‰ï¼šæ‰¹å¤„ç† token çš„å†…éƒ¨ batch size, ä¹Ÿå°±æ˜¯æ¯æ¬¡åŒæ—¶è½¬æ¢å¤šå°‘ä¸ªtoken
)
```

```bash
âœ… Using device: cuda
ğŸ“‚ Loading checkpoint: models/model_vq_8k_epoch10.pth
ğŸ¯ Inferred: codebook_size=8192, dim=64
âœ… VQTokenizer initialized:
   Checkpoint       : ...
   Device           : cuda
   Codebook size    : 8192
   Latent dim       : 64
   Downsample rate  : 5
   Chunk size       : 500
   Margin           : 25 samples
```
æ³¨æ„ï¼šdownsample_rateã€chunk_sizeã€margin ç­‰å‚æ•°ç”±æ¨¡å‹ checkpoint è‡ªåŠ¨æ¨æ–­ï¼Œä¸å¯æ‰‹åŠ¨è¦†ç›–

### å¯¹ä¸€æ®µä¿¡å·è¿›è¡ŒtokenåŒ–-é»˜è®¤å¼€å¯huadaå½’ä¸€åŒ–

```python

import numpy as np

# æ¨¡æ‹Ÿä¸€æ®µä¿¡å·ï¼ˆå•ä½ï¼špAï¼Œé•¿åº¦ä»»æ„ â‰¥ 25ï¼‰
signal = np.random.randn(1000).astype(np.float32) * 5 + 100

# é»˜è®¤è¿”å› token åˆ—è¡¨ï¼ˆæ¯ä¸ªå…ƒç´ æ˜¯å­—ç¬¦ä¸²ï¼Œå¦‚ "<|bwav:1234|>"ï¼‰
tokens_list = tokenizer.tokenize_data(signal)
print(len(tokens_list))        # è¾“å‡º token æ•°é‡
print("".join(tokens_list[:10]))  # æ‹¼æ¥å‰10ä¸ª token
```

### å¯¹ä¸€æ®µä¿¡å·è¿›è¡ŒtokenåŒ–-å…³é—­å½’ä¸€åŒ–


```
import numpy as np

# æ¨¡æ‹Ÿä¸€æ®µä¿¡å·ï¼ˆå•ä½ï¼špAï¼Œé•¿åº¦ä»»æ„ â‰¥ 25ï¼‰
signal = np.random.randn(1000).astype(np.float32) * 5 + 100

# é»˜è®¤è¿”å› L1 å±‚çº§çš„ token åˆ—è¡¨ï¼ˆæ¯ä¸ªå…ƒç´ æ˜¯å­—ç¬¦ä¸²ï¼Œå¦‚ "<|bwav:1234|>"ï¼‰
tokens_list = tokenizer.tokenize_data(signal, do_normalize=False)
print(len(tokens_list))        # è¾“å‡º token æ•°é‡
print("".join(tokens_list[:10]))  # æ‹¼æ¥å‰10ä¸ª token
```

### å¯¹ä¸€æ®µä¿¡å·è¿›è¡ŒtokenåŒ–-å¯ç”¨ä¸­å€¼æ»¤æ³¢(çª—å£ä¸º5) å’Œä½é€šé›¶ç›¸ä½æ»¤æ³¢ï¼ˆæˆªè‡³é¢‘ç‡ä¸º1000HZï¼‰

```
# åŒæ—¶å¯ç”¨ä¸­å€¼æ»¤æ³¢ï¼ˆmedfï¼‰å’Œä½é€šæ»¤æ³¢ï¼ˆlpfï¼‰
tokens_list = tokenizer.tokenize_data(signal, medf=5, lpf=1000)

print(len(tokens_list))  # æ€» token æ•° = 4 Ã— (æœ‰æ•ˆä¿¡å·å—æ•°)
print("".join(tokens_list[:20]))
```

### å¦‚æœä¼ å…¥ä¿¡å·å°‘äº25ä¸ªï¼Œè¿”å›ç©ºçš„list


### å¯¹ä¸€ä¸ªfast5æ–‡ä»¶è¿›è¡ŒtokenåŒ–
æ–‡ä»¶è‡ªåŠ¨ gzip å‹ç¼©ï¼ˆ.gz åç¼€ï¼‰
è‡ªåŠ¨è·³è¿‡æ— æ•ˆæˆ–è¿‡çŸ­çš„ reads
æ”¯æŒ single-read å’Œ multi-read FAST5

```
tokenizer.tokenize_fast5(
    fast5_path="data/sample.fast5",
    output_path="output/sample.jsonl.gz"
)
```

è¾“å‡ºçš„jsonl.gzå†…å®¹æ ¼å¼

```
{"id": "read_12345", "text": "<|bwav:5808|><|bwav:702|><|bwav:330|>..."}
{"id": "read_67890", "text": "<|bwav:2432|><|bwav:812|>..."}
```

## Kmeans Tokenizer



## RVQ Tokenizer




1. é¢„è®­ç»ƒæ¨¡å‹å‡†å¤‡
RVQ Tokenizerï¼šå°†é¢„è®­ç»ƒ checkpoint æ–‡ä»¶ï¼ˆå¦‚ nanopore_rvq_tokenizer_chunk12k.pthï¼‰æ”¾å…¥é¡¹ç›® models/ ç›®å½•ï¼›
KMeans Tokenizerï¼šç›´æ¥ä½¿ç”¨ models/ ç›®å½•ä¸‹çš„ centroids.npy èšç±»ä¸­å¿ƒæ–‡ä»¶ã€‚
2. ä¿¡å· Token åŒ–ç¤ºä¾‹
RVQ Tokenizer ä½¿ç”¨ç¤ºä¾‹ï¼šå‚è€ƒ test/ ç›®å½•ä¸‹ example_rvq_tokenizer_data.pyï¼›
KMeans Tokenizer ä½¿ç”¨ç¤ºä¾‹ï¼šå‚è€ƒ test/ ç›®å½•ä¸‹ example_kmeans_tokenize_data.pyã€‚

