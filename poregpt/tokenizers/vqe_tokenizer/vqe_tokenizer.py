# nanopore_signal_tokenizer/vq_tokenizer.py
# Suppress known deprecation warnings

import warnings
warnings.filterwarnings(
    "ignore",
    message=".*pkg_resources is deprecated.*",
    category=UserWarning,
    module="ont_fast5_api"
)

import os
import json
import gzip
import numpy as np
import torch
from math import ceil
from ont_fast5_api.fast5_interface import get_fast5_file
from ...utils.signal import nanopore_process_signal
from tqdm import tqdm
from scipy.signal import medfilt
import numpy as np
from typing import List

import numpy as np
from typing import List


# Import your model definition (must define NanoporeVQModel)
from .vq_model import NanoporeVQModel


class VQETokenizer:
    """
    Nanopore Single-Layer VQ Tokenizer.
    - Uses VectorQuantize (not RVQ)
    - No reconstruction loss needed
    - Designed for diversity + waveform backbone retention
    """

    def __init__(
        self,
        model_ckpt: str = "nanopore_vq_tokenizer.pth",
        device: str = "cuda",
        token_batch_size: int = 8000,
    ):
        # --- Device setup ---
        if device is None:
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            device = device.strip()
            if device.startswith("cuda"):
                if not torch.cuda.is_available():
                    print("âš ï¸ CUDA not available, falling back to CPU.")
                    self.device = "cpu"
                else:
                    self.device = device
            elif device == "cpu":
                self.device = "cpu"
            else:
                raise ValueError(f"Unsupported device: {device}")
        
        print(f"âœ… Using device: {self.device}")

        # --- Load checkpoint ---
        print(f"ğŸ“‚ Loading checkpoint: {model_ckpt}")
        ckpt_data = torch.load(model_ckpt, map_location="cpu",weights_only=False)

        # âœ… 1. ä» checkpoint ä¸­è¯»å– cnn_typeï¼ˆå…³é”®ï¼ï¼‰
        if 'cnn_type' not in ckpt_data:
            print("Checkpoint does not contain 'cnn_type'. forced to 0")
            cnn_type = 0
        else:
            cnn_type = ckpt_data['cnn_type']

        # âœ… æ­£ç¡®ï¼šä» model_state_dict ä¸­æ‰¾ codebook
        state_dict = ckpt_data['model_state_dict']
        embed_keys = [k for k in state_dict.keys() if "_codebook.embed" in k]
        if not embed_keys:
            raise RuntimeError("No codebook embedding found in checkpoint.")

        # Assume single quantizer: key like 'quantizer._codebook.embed'
        embed_key = embed_keys[0]
        embed_tensor = state_dict[embed_key]  # shape: [codebook_size, dim] or [1, codebook_size, dim]

        if len(embed_tensor.shape) == 3:
            codebook_size = int(embed_tensor.shape[1])
            dim = int(embed_tensor.shape[2])
        elif len(embed_tensor.shape) == 2:
            codebook_size = int(embed_tensor.shape[0])
            dim = int(embed_tensor.shape[1])
        else:
            raise RuntimeError(f"Unexpected codebook shape: {embed_tensor.shape}")

        self.codebook_size = codebook_size
        self.dim = dim
        print(f"ğŸ¯ Inferred: codebook_size={codebook_size}, dim={dim}, cnn_type={cnn_type}")

        # --- Instantiate model ---
        self.model = NanoporeVQModel(codebook_size=codebook_size,cnn_type=cnn_type)

        if not hasattr(self.model, 'cnn_stride'):
            raise AttributeError("Model must define 'cnn_stride' (total downsampling rate).")
        if not hasattr(self.model, 'margin_stride_count'):
            self.model.margin_stride_count = 2  # default fallback

        self.downsample_rate = self.model.cnn_stride
        self.margin_stride_count = self.model.margin_stride_count
        self.margin = self.margin_stride_count * self.downsample_rate
        self.model_RF = self.model.RF
        if token_batch_size < 1:
            token_batch_size = 1
        self.chunk_size = token_batch_size * self.downsample_rate

        # --- Load state dict ---
        self.model.load_state_dict(state_dict)
        self.model.eval()
        self.model.to(self.device)

        print("\nâœ… VQTokenizer initialized:")
        print(f"   Checkpoint       : {os.path.abspath(model_ckpt)}")
        print(f"   Device           : {self.device}")
        print(f"   Codebook size    : {self.codebook_size}")
        print(f"   Latent dim       : {self.dim}")
        print(f"   Downsample rate  : {self.downsample_rate}")
        print(f"   Chunk size       : {self.chunk_size}")
        print(f"   Margin           : {self.margin} samples")
        print("-" * 60)
    

    def _tokenize_chunked_signal(self, signal: np.ndarray) -> np.ndarray:
        """Tokenize 1D signal using sliding window with margin."""
        if signal.ndim != 1:
            raise ValueError("Signal must be 1D.")
        L = len(signal)
        if L < self.model_RF:
            return np.array([], dtype=np.int64)

        if L == 0:
            return np.array([], dtype=np.int64)

        T_expected = (L + self.downsample_rate - 1) // self.downsample_rate

        if L <= self.chunk_size:
            padded = np.pad(signal, (0, self.chunk_size - L), mode='constant')
            x = torch.from_numpy(padded).float().unsqueeze(0).unsqueeze(0).to(self.device)
            with torch.no_grad():
                recon,tokens,loss,loss_breakdown = self.model(x)  # returns [B, T] or [B, T, 1] â†’ squeeze to [T]
            tokens = tokens.squeeze(0).cpu().numpy()
            if tokens.ndim == 2:
                tokens = tokens[:, 0]  # take first (and only) layer
            return tokens[:T_expected].astype(np.int64)

        # Long signal: sliding window
        margin_samples = self.margin
        step_samples = self.chunk_size - 2 * margin_samples
        if step_samples <= 0:
            raise ValueError("chunk_size too small for margin.")

        all_tokens = []
        start = 0
        chunk_index = 0

        while start < L:
            real_len = min(self.chunk_size, L - start)
            chunk = signal[start:start + real_len]
            if len(chunk) < self.chunk_size:
                chunk = np.pad(chunk, (0, self.chunk_size - len(chunk)), mode='constant')
            x = torch.from_numpy(chunk).float().unsqueeze(0).unsqueeze(0).to(self.device)
            with torch.no_grad():
                recon,tokens,loss,loss_breakdown = self.model(x)
            tokens = tokens.squeeze(0).cpu().numpy()
            if tokens.ndim == 2:
                tokens = tokens[:, 0]
            T_valid = (real_len + self.downsample_rate - 1) // self.downsample_rate
            kept_tokens = np.array([], dtype=np.int64)
            if chunk_index == 0:
                end_idx = T_valid - self.margin_stride_count if self.margin_stride_count > 0 else T_valid
                kept_tokens = tokens[:max(0, end_idx)]
            elif start + step_samples >= L:
                start_idx = self.margin_stride_count
                max_len = T_valid - self.margin_stride_count
                if max_len > 0:
                    kept_tokens = tokens[start_idx : start_idx + max_len]
            else:
                if self.margin_stride_count > 0 and len(tokens) > 2 * self.margin_stride_count:
                    max_len = T_valid - 2 * self.margin_stride_count
                    if max_len > 0:
                        kept_tokens = tokens[
                            self.margin_stride_count : self.margin_stride_count + max_len
                        ]
                else:
                    kept_tokens = tokens[:T_valid]

            if kept_tokens.size > 0:
                all_tokens.append(kept_tokens)

            start += step_samples
            chunk_index += 1

        if not all_tokens:
            return np.zeros(T_expected, dtype=np.int64)

        final_tokens = np.concatenate(all_tokens, axis=0)
        if len(final_tokens) > T_expected:
            final_tokens = final_tokens[:T_expected]
        elif len(final_tokens) < T_expected:
            final_tokens = np.pad(final_tokens, (0, T_expected - len(final_tokens)), constant_values=0)

        return final_tokens.astype(np.int64)


    def tokenize_signal_batched(self, 
                           signal: np.ndarray, 
                           signal_chunk_size: int, 
                           signal_chunk_overlap_size: int, 
                           max_batch_size: int) -> List[np.ndarray]:
        """
        å°†ä¿¡å·ä¸¥æ ¼åˆ‡åˆ†ä¸ºç­‰é•¿å—ï¼ˆä¸è¶³é•¿åº¦çš„ç›´æ¥ä¸¢å¼ƒï¼‰ï¼Œå¹¶æŒ‰æ‰¹æ¬¡è¿›è¡Œæ¨ç†ã€‚
        ä½¿ç”¨ extendï¼Œè¿”å›çš„æ˜¯ä¸€ç»´åˆ—è¡¨ï¼ˆæ‰€æœ‰å—çš„ tokens è¿åœ¨ä¸€èµ·ï¼‰ã€‚
        
        Args:
            signal: è¾“å…¥çš„ä¸€ç»´ä¿¡å·æ•°ç»„ã€‚
            signal_chunk_size: æ¯ä¸ªå—çš„ä¸¥æ ¼å¤§å°ã€‚
            signal_chunk_overlap_size: å—ä¹‹é—´çš„é‡å å¤§å°ã€‚
            max_batch_size: æ¯ä¸ªæ¨ç†æ‰¹æ¬¡çš„æœ€å¤§å—æ•°é‡ã€‚
            
        Returns:
            List[np.ndarray]: ä¸€ç»´åˆ—è¡¨ã€‚æ¯ä¸ªå…ƒç´ æ˜¯å•ä¸ªå—çš„æ¨ç†ç»“æœ (tokens)ã€‚
                             (æ³¨æ„ï¼šä¸å†æ˜¯äºŒç»´åˆ—è¡¨ï¼Œæ‰€æœ‰æ‰¹æ¬¡çš„æ•°æ®éƒ½è¢«åˆå¹¶åˆ°äº†åŒä¸€ä¸ªåˆ—è¡¨ä¸­)
        """
    
        if signal.ndim != 1:
            raise ValueError("Signal must be 1D.")
        
        L = len(signal)
        batched_results = [] # åˆå§‹åŒ–ç»“æœåˆ—è¡¨
        
        # --- æƒ…å†µ 1: ä¿¡å·æ€»é•¿åº¦å°äºä¸€ä¸ªå—çš„å¤§å° ---
        if L < signal_chunk_size:
            return batched_results

        # --- æƒ…å†µ 2: ä¿¡å·è¶³å¤Ÿé•¿ï¼Œè¿›è¡Œä¸¥æ ¼åˆ‡åˆ† ---
        step_size = signal_chunk_size - signal_chunk_overlap_size
        if step_size <= 0:
            raise ValueError("signal_chunk_size must be greater than signal_chunk_overlap_size.")
        
        # 1. ç¬¬ä¸€é˜¶æ®µï¼šä¸¥æ ¼åˆ‡åˆ† (ä¸å¡«å……)
        chunks = []
        start = 0    
        while start + signal_chunk_size <= L:
            chunk = signal[start : start + signal_chunk_size]
            chunks.append(chunk)
            start += step_size

        if not chunks:
            return batched_results

        # 2. ç¬¬äºŒé˜¶æ®µï¼šæ‰¹é‡æ¨ç†
        for i in range(0, len(chunks), max_batch_size):
            batch_chunks = chunks[i : i + max_batch_size]
            
            # --- æ ¸å¿ƒæ¨ç†ä»£ç  ---
            batch_np = np.array(batch_chunks)
            x = torch.from_numpy(batch_np).float().unsqueeze(1).to(self.device)
            
            with torch.no_grad():
                recon, tokens, loss, loss_breakdown = self.model(x) 
            
            tokens_np = tokens.cpu().numpy()
            if tokens_np.ndim == 3:
                tokens_np = tokens_np.squeeze(-1) # [B, T, 1] -> [B, T]
            
            # --- ä¿®æ”¹ç‚¹ï¼šä½¿ç”¨ extend ---
            # å°†å½“å‰æ‰¹æ¬¡ä¸­æ¯ä¸€ä¸ªå—çš„ tokens ç»“æœç›´æ¥æ·»åŠ åˆ°ä¸»åˆ—è¡¨ä¸­
            # è¿™æ ·åšä¼šâ€œå±•å¹³â€æ‰¹æ¬¡ç»“æ„ï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªåŒ…å«æ‰€æœ‰å—ç»“æœçš„ä¸€ç»´åˆ—è¡¨
            batched_results.extend(tokens_np)
            # -------------------------
            
        return batched_results # è¿”å› List[np.ndarray] (ä¸€ç»´)


    # tokenize_dataä¸æ”¯æŒä»»ä½•å½’ä¸€åŒ–, medf, lpfç­‰æ“ä½œ
    def tokenize_data(self, signal: np.ndarray) -> list:
        flat_tokens = self._tokenize_chunked_signal(signal)
        if flat_tokens.size == 0:
            return []
        parts = []
        for token_id in flat_tokens:
            parts.append(f"<|bwav:{int(token_id)}|>")
        return parts


    def tokenize_read(self, read, nanopore_signal_process_strategy="apple") -> list:
        try:
            channel_info = read.handle[read.global_key + 'channel_id'].attrs
            offset = int(channel_info['offset'])
            scaling = channel_info['range'] / channel_info['digitisation']
            raw = read.handle[read.raw_dataset_name][:]
            signal_raw = np.array(scaling * (raw + offset), dtype=np.float32)
            signal_processed = nanopore_process_signal(signal_raw,nanopore_signal_process_strategy)
            return self.tokenize_data(signal_processed)
        except Exception as e:
            fast5_path = getattr(read.handle, 'filename', 'unknown.fast5')
            print(f"âŒ Error on read {read.read_id} in {fast5_path}: {e}")
            return []
    

    def tokenize_fast5(self, fast5_path: str, output_path:str, nanopore_signal_process_strategy="apple"):
        print(f"âœ… Processing {fast5_path} with strategy{nanopore_signal_process_strategy}")
        results = []
        with get_fast5_file(fast5_path, mode="r") as f5:
            for read in tqdm(f5.get_reads(), desc=os.path.basename(fast5_path)):
                try:
                    token_list = self.tokenize_read(read,nanopore_signal_process_strategy)
                    token_str = "".join(token_list)
                    results.append({"id": read.read_id, "text": token_str})
                except Exception as e:
                    print(f"âŒ Failed on read {read.read_id}: {e}")
                    continue

        with gzip.open(output_path, 'wt', encoding='utf-8') as f:
            for item in results:
                f.write(json.dumps(item) + '\n')
        print(f"âœ… Wrote {len(results)} reads to {output_path}")

    def tokenize_data_batched(self, 
                 signal: np.ndarray, 
                 signal_chunk_size: int, 
                 signal_chunk_overlap_size: int, 
                 max_batch_size: int,
                 chunk_token_count: int) -> list:
        """
        ä½¿ç”¨æ‰¹é‡æ¨ç†å‡½æ•°è·å– tokensï¼Œå¹¶è¿›è¡Œä¸¥æ ¼æ ¡éªŒä¸æ‹¼æ¥ã€‚
        
        Args:
            signal: è¾“å…¥ä¿¡å·
            signal_chunk_size: ä¿¡å·å—å¤§å°
            signal_chunk_overlap_size: é‡å å¤§å°
            max_batch_size: æœ€å¤§æ‰¹å¤§å°
            chunk_token_count: æœŸæœ›æ¯ä¸ª chunk è¾“å‡ºçš„ token æ•°é‡ (ç”¨äºæ ¡éªŒ)
            
        Returns:
            list: æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œç”±ç¬¦åˆé•¿åº¦è¦æ±‚çš„ chunk tokens æ‹¼æ¥è€Œæˆ
        """
        
        # è°ƒç”¨æ‰¹é‡å¤„ç†å‡½æ•°
        chunks_tokens_list = self.tokenize_signal_batched(
            signal=signal,
            signal_chunk_size=signal_chunk_size,       
            signal_chunk_overlap_size=signal_chunk_overlap_size, 
            max_batch_size=max_batch_size
        )
        
        # å¦‚æœæ²¡æœ‰ç»“æœï¼Œè¿”å›ç©ºåˆ—è¡¨
        if not chunks_tokens_list:
            return []

        string_parts = []
        for chunk_tokens in chunks_tokens_list:
            # --- æ–°å¢æ ¡éªŒé€»è¾‘ ---
            # æ£€æŸ¥å½“å‰ chunk çš„ token æ•°é‡æ˜¯å¦ç¬¦åˆé¢„æœŸ
            if len(chunk_tokens) != chunk_token_count:
                # å¦‚æœé•¿åº¦ä¸ç¬¦ï¼Œå¯ä»¥é€‰æ‹©è·³è¿‡(this)ã€å¡«å……æˆ–æŠ¥é”™
                # è¿™é‡Œé€‰æ‹©è·³è¿‡ï¼Œä¸åŠ å…¥ç»“æœåˆ—è¡¨
                continue 
            
            # 1. å°†æ¯ä¸ª token ID è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
            token_strings = [f"<|bwav:{int(token_id)}|>" for token_id in chunk_tokens]
            # 2. ä½¿ç”¨ "".join() æ‹¼æ¥
            joined_string = "".join(token_strings)
            string_parts.append(joined_string)
        return string_parts

    def tokenize_read_batched(self, read, 
        nanopore_signal_process_strategy:str="apple",
        # æ–°å¢å‚æ•°ï¼šç”¨äºä¼ é€’ç»™ tokenize_data
        signal_chunk_size: int = 40000,
        signal_chunk_overlap_size: int = 10000,
        max_batch_size: int = 32,
        chunk_token_count: int = 8000 # ç”¨äºå†…éƒ¨æ ¡éªŒ
    ) -> list:
        try:
            channel_info = read.handle[read.global_key + 'channel_id'].attrs
            offset = int(channel_info['offset'])
            scaling = channel_info['range'] / channel_info['digitisation']
            raw = read.handle[read.raw_dataset_name][:]
            signal_raw = np.array(scaling * (raw + offset), dtype=np.float32)
            signal_processed = nanopore_process_signal(signal_raw,nanopore_signal_process_strategy)
            return self.tokenize_data_batched(signal_processed,signal_chunk_size,signal_chunk_overlap_size,max_batch_size,chunk_token_count)
        except Exception as e:
            fast5_path = getattr(read.handle, 'filename', 'unknown.fast5')
            print(f"âŒ Error on read {read.read_id} in {fast5_path}: {e}")
            return []



    def tokenize_fast5_batched(self,
        fast5_path: str,
        output_path: str,
        nanopore_signal_process_strategy="apple",
        # æ–°å¢å‚æ•°ï¼šç”¨äºä¼ é€’ç»™ tokenize_data
        signal_chunk_size: int = 40000,
        signal_chunk_overlap_size: int = 10000,
        max_batch_size: int = 32,
        chunk_token_count: int = 8000 # ç”¨äºå†…éƒ¨æ ¡éªŒ
    ):
        print(f"âœ… Processing {fast5_path} with strategy {nanopore_signal_process_strategy}")
        results = []

        with get_fast5_file(fast5_path, mode="r") as f5:
            for read in tqdm(f5.get_reads(), desc=os.path.basename(fast5_path)):
                try:
                    # è°ƒç”¨ tokenize_dataï¼Œä¼ å…¥æ‰€æœ‰å¿…è¦çš„å‚æ•°
                    # è¿”å›çš„æ˜¯ List[str]ï¼Œä¾‹å¦‚ ["<|bwav:1|><|bwav:2|>", "<|bwav:3|><|bwav:4|>"]
                    chunked_token_strings = self.tokenize_read_batched(
                        read=read,
                        signal_chunk_size=signal_chunk_size,
                        signal_chunk_overlap_size=signal_chunk_overlap_size,
                        max_batch_size=max_batch_size,
                        chunk_token_count=chunk_token_count
                    )
                    # --- ä¿®æ”¹å¼€å§‹ ---
                    # å¾ªç¯æ¯ä¸ªåˆ†å—å­—ç¬¦ä¸²ï¼Œä½œä¸ºç‹¬ç«‹è¡Œè¿½åŠ 
                    for chunk_token_str in chunked_token_strings:
                        results.append({
                            "id": read.read_id, 
                            "text": chunk_token_str
                        })
                    # --- ä¿®æ”¹ç»“æŸ ---
                    # å°†å¤šä¸ª chunk çš„å­—ç¬¦ä¸²ç”¨ç©ºæ ¼ï¼ˆæˆ–å…¶ä»–åˆ†éš”ç¬¦ï¼‰è¿æ¥æˆä¸€ä¸ªå®Œæ•´çš„å­—ç¬¦ä¸²
                    # å¦‚æœä¸éœ€è¦åˆ†éš”ç¬¦ï¼Œä½¿ç”¨ ""ï¼›å¦‚æœéœ€è¦åŒºåˆ† chunk è¾¹ç•Œï¼Œå»ºè®®ä½¿ç”¨ " " æˆ– "<|chunk_end|>"
                except Exception as e:
                    print(f"âŒ Failed on read {read.read_id}: {e}")
                    continue

        # å†™å…¥æ–‡ä»¶
        with gzip.open(output_path, 'wt', encoding='utf-8') as f:
            for item in results:
                f.write(json.dumps(item) + '\n')
        print(f"âœ… Wrote {len(results)} reads to {output_path}")
