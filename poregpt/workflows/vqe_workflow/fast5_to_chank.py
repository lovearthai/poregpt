import os
import numpy as np
from ont_fast5_api.fast5_interface import get_fast5_file
from tqdm import tqdm
from multiprocessing import Pool, cpu_count
import traceback
from pathlib import Path
from poregpt.utils.signal import nanopore_process_signal
import argparse


def process_single_fast5(args):
    """
    å¤„ç†å•ä¸ª fast5 æ–‡ä»¶ï¼Œå°†å…¶ä¿¡å·æ•°æ®åˆ‡åˆ†å¹¶ä¿å­˜ä¸º numpy æ•°ç»„
    
    Args:
        args (tuple): åŒ…å«ä»¥ä¸‹å‚æ•°çš„å…ƒç»„
            - fast5_path (str): è¾“å…¥ fast5 æ–‡ä»¶è·¯å¾„
            - output_dir (str): è¾“å‡ºç›®å½•è·¯å¾„
            - nanopore_signal_process_strategy (str): ä¿¡å·å¤„ç†ç­–ç•¥
            - signal_chunk_size (int): ä¿¡å·å—å¤§å°
            - signal_chunk_overlap_size (int): é‡å å¤§å°
    
    Returns:
        str: å¤„ç†ç»“æœä¿¡æ¯å­—ç¬¦ä¸²
    """
    fast5_path, output_dir, nanopore_signal_process_strategy, signal_chunk_size, signal_chunk_overlap_size = args
    
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        # å­˜å‚¨å¤„ç†åçš„æ•°æ®å—
        processed_chunks = []
        
        # è¯»å– fast5 æ–‡ä»¶
        with get_fast5_file(fast5_path, mode="r") as f5:
            for read in f5.get_reads():
                try:
                    # ä» fast5 æ–‡ä»¶ä¸­æå–åŸå§‹ä¿¡å·æ•°æ®
                    channel_info = read.handle[read.global_key + 'channel_id'].attrs
                    offset = int(channel_info['offset'])
                    scaling = channel_info['range'] / channel_info['digitisation']
                    raw = read.handle[read.raw_dataset_name][:]
                    signal_raw = np.array(scaling * (raw + offset), dtype=np.float32)
                    
                    # åº”ç”¨ä¿¡å·å¤„ç†ç­–ç•¥
                    signal_processed = nanopore_process_signal(signal_raw, nanopore_signal_process_strategy)
                    
                    # å°†å¤„ç†åçš„ä¿¡å·æŒ‰æŒ‡å®šå¤§å°åˆ‡åˆ†
                    L = len(signal_processed)
                    step_size = signal_chunk_size - signal_chunk_overlap_size
                    
                    # ç¡®ä¿ä¿¡å·é•¿åº¦è¶³å¤Ÿå¤„ç†
                    if L >= signal_chunk_size:
                        start = 0
                        chunk_idx = 0
                        
                        # æŒ‰æ­¥é•¿æ»‘åŠ¨çª—å£åˆ‡åˆ†ä¿¡å·
                        while start + signal_chunk_size <= L:
                            chunk = signal_processed[start : start + signal_chunk_size]
                            
                            # å°†å½“å‰å—ä¿¡æ¯æ·»åŠ åˆ°åˆ—è¡¨ä¸­
                            processed_chunks.append({
                                'read_id': read.read_id,
                                'chunk_idx': chunk_idx,
                                'chunk': chunk
                            })
                            
                            start += step_size
                            chunk_idx += 1
                    
                except Exception as e:
                    print(f"âŒ Failed on read {read.read_id} in {fast5_path}: {e}")
                    continue
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åï¼ˆå°† fast5 æ‰©å±•åæ›¿æ¢ä¸º npyï¼‰
        base_name = Path(fast5_path).stem
        output_file = os.path.join(output_dir, f"{base_name}.npy")
        
        # ä¿å­˜æ‰€æœ‰å¤„ç†åçš„æ•°æ®å—
        if processed_chunks:
            # æå–æ‰€æœ‰æ•°æ®å—ï¼Œå¿½ç•¥å…ƒæ•°æ®ä¿¡æ¯
            chunks_data = [item['chunk'] for item in processed_chunks]
            np.save(output_file, chunks_data)
        
        return f"âœ… Processed {fast5_path} -> {output_file} ({len(processed_chunks)} chunks)"
        
    except Exception as e:
        error_msg = f"âŒ Error processing {fast5_path}: {str(e)}\n{traceback.format_exc()}"
        return error_msg


def convert_fast5_to_npy_parallel(
    input_dir,
    output_dir,
    nanopore_signal_process_strategy="apple",
    signal_chunk_size=40000,
    signal_chunk_overlap_size=10000,
    num_processes=None
):
    """
    å¹¶è¡Œè½¬æ¢ç›®å½•ä¸­æ‰€æœ‰ fast5 æ–‡ä»¶ä¸º npy æ–‡ä»¶
    
    è¯¥å‡½æ•°éå†è¾“å…¥ç›®å½•åŠå…¶æ‰€æœ‰å­ç›®å½•ï¼Œæ‰¾åˆ°æ‰€æœ‰ fast5 æ–‡ä»¶ï¼Œ
    å¯¹æ¯ä¸ªæ–‡ä»¶åº”ç”¨ä¿¡å·å¤„ç†ç­–ç•¥å¹¶æŒ‰æŒ‡å®šå¤§å°åˆ‡åˆ†ï¼Œæœ€ç»ˆä¿å­˜ä¸º numpy æ•°ç»„æ ¼å¼
    
    Args:
        input_dir (str): è¾“å…¥ç›®å½•è·¯å¾„ï¼ŒåŒ…å« fast5 æ–‡ä»¶
        output_dir (str): è¾“å‡ºç›®å½•è·¯å¾„ï¼Œç”¨äºä¿å­˜ npy æ–‡ä»¶
        nanopore_signal_process_strategy (str): ä¿¡å·å¤„ç†ç­–ç•¥åç§°
        signal_chunk_size (int): æ¯ä¸ªä¿¡å·å—çš„å¤§å°ï¼Œé»˜è®¤ 40000
        signal_chunk_overlap_size (int): ä¿¡å·å—ä¹‹é—´çš„é‡å å¤§å°ï¼Œé»˜è®¤ 10000
        num_processes (int, optional): å¹¶è¡Œè¿›ç¨‹æ•°ï¼Œé»˜è®¤ä¸º CPU æ ¸å¿ƒæ•°
    
    Returns:
        None
    """
    # è®¾ç½®é»˜è®¤è¿›ç¨‹æ•°ä¸º CPU æ ¸å¿ƒæ•°
    if num_processes is None:
        num_processes = cpu_count()
    
    # æŸ¥æ‰¾æ‰€æœ‰ fast5 æ–‡ä»¶ï¼ˆåŒ…æ‹¬ .fast5 å’Œ .fasta5 æ‰©å±•åï¼‰
    input_path = Path(input_dir)
    fast5_files = list(input_path.rglob("*.fast5")) + list(input_path.rglob("*.fasta5"))
    
    # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°ä»»ä½• fast5 æ–‡ä»¶
    if not fast5_files:
        print(f"âš ï¸ No fast5 files found in {input_dir}")
        return
    
    print(f"Found {len(fast5_files)} fast5 files")
    print(f"Using {num_processes} processes")
    
    # å‡†å¤‡å‚æ•°åˆ—è¡¨ç”¨äºå¤šè¿›ç¨‹å¤„ç†
    args_list = [
        (str(fast5_file), output_dir, nanopore_signal_process_strategy, signal_chunk_size, signal_chunk_overlap_size)
        for fast5_file in fast5_files
    ]
    
    # ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œå¤„ç†æ‰€æœ‰ fast5 æ–‡ä»¶
    with Pool(num_processes) as pool:
        results = list(tqdm(
            pool.imap_unordered(process_single_fast5, args_list),
            total=len(args_list),
            desc="Processing fast5 files"
        ))
    
    # ç»Ÿè®¡å¤„ç†ç»“æœ
    success_count = sum(1 for r in results if r.startswith("âœ…"))
    error_count = len(results) - success_count
    
    print(f"\nğŸ“Š Summary:")
    print(f"   Success: {success_count}")
    print(f"   Errors:  {error_count}")
    print(f"   Total:   {len(results)}")


def main():
    """
    ä¸»å‡½æ•° - å·¥ä¸šçº§ fast5 åˆ° npy è½¬æ¢å™¨å…¥å£ç‚¹
    
    é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æ¥æ”¶ç”¨æˆ·é…ç½®ï¼Œæ‰§è¡Œ fast5 æ–‡ä»¶åˆ° npy æ•°ç»„çš„æ‰¹é‡è½¬æ¢ã€‚
    æ”¯æŒè‡ªå®šä¹‰ä¿¡å·å¤„ç†ç­–ç•¥ã€å—å¤§å°ã€é‡å å¤§å°å’Œå¹¶è¡Œè¿›ç¨‹æ•°ã€‚
    """
    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(
        description="Convert fast5 files to npy arrays with signal processing and chunking",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s -i /path/to/fast5/ -o /path/to/output/
  %(prog)s -i /data/fast5/ -o /data/processed/ -s apple -c 50000 -ov 15000 -p 16
        """
    )
    
    # æ·»åŠ å¿…éœ€å‚æ•°
    parser.add_argument(
        '-i', '--input-dir',
        type=str,
        required=True,
        help='Input directory containing fast5 files (searches recursively)'
    )
    
    parser.add_argument(
        '-o', '--output-dir',
        type=str,
        required=True,
        help='Output directory to save npy files'
    )
    
    # æ·»åŠ å¯é€‰å‚æ•°
    parser.add_argument(
        '-s', '--strategy',
        type=str,
        default='apple',
        choices=['apple', 'med_flt', 'lp_flt'],  # å‡è®¾è¿™äº›æ˜¯æ”¯æŒçš„ç­–ç•¥
        help='Nanopore signal processing strategy (default: apple)'
    )
    
    parser.add_argument(
        '-c', '--chunk-size',
        type=int,
        default=40000,
        help='Size of each signal chunk (default: 40000)'
    )
    
    parser.add_argument(
        '-ov', '--overlap-size',
        type=int,
        default=10000,
        help='Overlap size between chunks (default: 10000)'
    )
    
    parser.add_argument(
        '-p', '--processes',
        type=int,
        default=None,
        help='Number of parallel processes (default: number of CPU cores)'
    )
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    
    # æ‰§è¡Œè½¬æ¢ä»»åŠ¡
    convert_fast5_to_npy_parallel(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        nanopore_signal_process_strategy=args.strategy,
        signal_chunk_size=args.chunk_size,
        signal_chunk_overlap_size=args.overlap_size,
        num_processes=args.processes
    )


if __name__ == "__main__":
    main()
